{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Общая информация**\n",
    "\n",
    "**Срок сдачи:** 21 октября 2019, 08:30 \n",
    "\n",
    "**Штраф за опоздание:** по 0.5 балла за 24 часа задержки. Через 10 дней домашнее задание сгорает.\n",
    "\n",
    "При отправлении ДЗ указывайте фамилию в названии файла\n",
    "Присылать ДЗ необходимо в виде ссылки на свой github репозиторий на почту ml1.sphere@mail.ru с указанием темы в следующем формате:\n",
    "\n",
    "[ML0919, Задание 1] Фамилия Имя.\n",
    "\n",
    "Используйте данный Ipython Notebook при оформлении домашнего задания."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Штрафные баллы:**\n",
    "\n",
    "1. Невыполнение PEP8 -0.5 баллов\n",
    "2. Отсутствие фамилии в имени скрипта (скрипт должен называться по аналогии со stroykova_hw1.ipynb) -0.5 баллов\n",
    "3. Все строчки должны быть выполнены. Нужно, чтобы output команды можно было увидеть уже в git'е. В противном случае -0.5 баллов\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pycodestyle_magic extension is already loaded. To reload it, use:\n",
      "  %reload_ext pycodestyle_magic\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn import datasets\n",
    "from sklearn.base import ClassifierMixin\n",
    "from sklearn.datasets import fetch_mldata, fetch_20newsgroups\n",
    "\n",
    "from sklearn.neighbors.base import NeighborsBase, KNeighborsMixin, SupervisedIntegerMixin \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import KDTree\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import tqdm\n",
    "%load_ext pycodestyle_magic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Задание 1 (1 балл)\n",
    "Реализовать KNN в классе MyKNeighborsClassifier (обязательное условие: точность не ниже sklearn реализации)\n",
    "Разберитесь самостоятельно, какая мера расстояния используется в KNeighborsClassifier дефолтно и реализуйте свой алгоритм именно с этой мерой. Самостоятельно разберитесь, как считается score из KNeighborsClassifier и реализуйте аналог в своём классе. Score не должен уступать значению KNN из sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-207-ab64ae7cdde4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pycodestyle'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\n\\nclass MyKNeighborsClassifier(NeighborsBase, KNeighborsMixin,\\n                             SupervisedIntegerMixin, ClassifierMixin):\\n    def __init__(self, n_neighbors, algorithm=\\'brute\\'):\\n        self._k = n_neighbors\\n        self.algorithm = algorithm\\n\\n    def __del__(self):\\n        del self.X\\n        del self.y\\n\\n    def fit(self, X, y):\\n        if y.shape[0] != X.shape[0]:\\n            print(\"wrong number of marks : y_train != X_train\")\\n        if X.shape[0] < 2:\\n            print(\"fit with one element...jopa\")\\n        self.X = np.array(X, dtype=\\'float\\')\\n        self.y = y\\n        \\'\\'\\'if type(X) == sp.sparse.csr.csr_matrix:\\n            if y.shape[0]!=X.shape[0]:\\n                print (\"wrong number of marks : y_train != X_train\")\\n            if X.shape[0]<2:\\n                print (\"fit with one element...jopa\")\\n            self.X = X\\n            self.y = y\\'\\'\\'\\n\\n    def predict(self, X):\\n        if self.algorithm == \\'brute\\':\\n            rez = np.zeros(np.shape(X)[0], dtype=int)\\n            dist_matrix = squareform(pdist(\\n                np.concatenate((X, self.X), axis=0)))[:len(X), len(X): : 1]\\n            ykn = np.argpartition(dist_matrix, range(self._k), axis = 1)[:, :self._k]\\n            for j in range(np.shape(X)[0]):\\n                classes, cl_count = np.unique(self.y[ykn[j, :]], return_counts = True)\\n                rez[j] = classes[np.argsort(cl_count)][-1]\\n            return rez\\n        if self.algorithm == \\'kd_tree\\':\\n            tree = KDTree(self.X, leaf_size=30)\\n            rez = np.zeros(np.shape(X)[0],dtype=int)\\n            distances, indexes = tree.query(X, k=self._k)\\n            for j in range(np.shape(X)[0]):\\n                classes, cl_count = np.unique(self.y[indexes[j]], return_counts = True)\\n                rez[j] = classes[np.argsort(cl_count)][-1]\\n            return rez\\n        \\'\\'\\'if type(X) == sp.sparse.csr.csr_matrix:\\n            tree = KDTree(self.X, leaf_size=30)\\n            rez=np.zeros(np.shape(X)[0],dtype=int)\\n                distances, indexes = tree.query(X, k=self._k)\\n                for j in range(np.shape(X)[0]):\\n                    classes, cl_count = np.unique(self.y[indexes[j]], return_counts = True)\\n                    rez[j] = classes[np.argsort(cl_count)][-1]\\n                return rez\\'\\'\\'\\n            \\n    def predict_proba(self, X):\\n        if self.algorithm == \\'brute\\':\\n            rez = np.zeros((np.shape(X)[0], len(np.unique(self.y))), dtype = float)\\n            dist_matrix = squareform(pdist(np.concatenate((X, self.X), axis = 0)))[:len(X),len(X): : 1]\\n            ykn = np.argpartition(dist_matrix, range(self._k), axis = 1)[:, :self._k]\\n            for j in range(np.shape(X)[0]):\\n                classes, cl_count = np.unique(self.y[ykn[j, :]], return_counts = True)\\n                rez[j, classes] = cl_count / np.sum(cl_count)\\n            return rez\\n        if self.algorithm == \\'kd_tree\\':\\n            tree = KDTree(self.X, leaf_size=30)\\n            rez = np.zeros((np.shape(X)[0], len(np.unique(self.y))), dtype = float)\\n            distances, indexes = tree.query(X, k=self._k)\\n            for j in tqdm.trange(np.shape(X)[0]):\\n                classes, cl_count = np.unique(self.y[indexes[j]], return_counts = True)\\n                rez[j, classes] = cl_count / np.sum(cl_count)\\n            return rez\\n            \\n    \\n    def score(self, X, y):\\n        return np.mean(self.predict(X)==y)\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/sphere-py37/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2357\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2358\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2359\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2360\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sphere-py37/lib/python3.7/site-packages/pycodestyle_magic.py\u001b[0m in \u001b[0;36mpycodestyle\u001b[0;34m(line, cell, auto)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;31m#logger.info(line)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;31m# on windows drive path also contains :\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m':'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m         \u001b[0;31m# only add + 1 for line for %%flake8, inc pre py3.6 string\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mauto\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "%%pycodestyle\n",
    "\n",
    "\n",
    "class MyKNeighborsClassifier(NeighborsBase, KNeighborsMixin,\n",
    "                             SupervisedIntegerMixin, ClassifierMixin):\n",
    "    def __init__(self, n_neighbors, algorithm='brute'):\n",
    "        self._k = n_neighbors\n",
    "        self.algorithm = algorithm\n",
    "\n",
    "    def __del__(self):\n",
    "        del self.X\n",
    "        del self.y\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        if y.shape[0] != X.shape[0]:\n",
    "            print(\"wrong number of marks : y_train != X_train\")\n",
    "        if X.shape[0] < 2:\n",
    "            print(\"fit with one element...jopa\")\n",
    "        self.X = np.array(X, dtype='float')\n",
    "        self.y = y\n",
    "        '''if type(X) == sp.sparse.csr.csr_matrix:\n",
    "            if y.shape[0]!=X.shape[0]:\n",
    "                print (\"wrong number of marks : y_train != X_train\")\n",
    "            if X.shape[0]<2:\n",
    "                print (\"fit with one element...jopa\")\n",
    "            self.X = X\n",
    "            self.y = y'''\n",
    "\n",
    "    def predict(self, X):\n",
    "        if self.algorithm == 'brute':\n",
    "            rez = np.zeros(np.shape(X)[0], dtype=int)\n",
    "            dist_matrix = squareform(pdist(\n",
    "                np.concatenate((X, self.X), axis=0)))[:len(X), len(X): : 1]\n",
    "            ykn = np.argpartition(dist_matrix, range(self._k), axis = 1)[:, :self._k]\n",
    "            for j in range(np.shape(X)[0]):\n",
    "                classes, cl_count = np.unique(self.y[ykn[j, :]], return_counts = True)\n",
    "                rez[j] = classes[np.argsort(cl_count)][-1]\n",
    "            return rez\n",
    "        if self.algorithm == 'kd_tree':\n",
    "            tree = KDTree(self.X, leaf_size=30)\n",
    "            rez = np.zeros(np.shape(X)[0],dtype=int)\n",
    "            distances, indexes = tree.query(X, k=self._k)\n",
    "            for j in range(np.shape(X)[0]):\n",
    "                classes, cl_count = np.unique(self.y[indexes[j]], return_counts = True)\n",
    "                rez[j] = classes[np.argsort(cl_count)][-1]\n",
    "            return rez\n",
    "        '''if type(X) == sp.sparse.csr.csr_matrix:\n",
    "            tree = KDTree(self.X, leaf_size=30)\n",
    "            rez=np.zeros(np.shape(X)[0],dtype=int)\n",
    "                distances, indexes = tree.query(X, k=self._k)\n",
    "                for j in range(np.shape(X)[0]):\n",
    "                    classes, cl_count = np.unique(self.y[indexes[j]], return_counts = True)\n",
    "                    rez[j] = classes[np.argsort(cl_count)][-1]\n",
    "                return rez'''\n",
    "            \n",
    "    def predict_proba(self, X):\n",
    "        if self.algorithm == 'brute':\n",
    "            rez = np.zeros((np.shape(X)[0], len(np.unique(self.y))), dtype = float)\n",
    "            dist_matrix = squareform(pdist(np.concatenate((X, self.X), axis = 0)))[:len(X),len(X): : 1]\n",
    "            ykn = np.argpartition(dist_matrix, range(self._k), axis = 1)[:, :self._k]\n",
    "            for j in range(np.shape(X)[0]):\n",
    "                classes, cl_count = np.unique(self.y[ykn[j, :]], return_counts = True)\n",
    "                rez[j, classes] = cl_count / np.sum(cl_count)\n",
    "            return rez\n",
    "        if self.algorithm == 'kd_tree':\n",
    "            tree = KDTree(self.X, leaf_size=30)\n",
    "            rez = np.zeros((np.shape(X)[0], len(np.unique(self.y))), dtype = float)\n",
    "            distances, indexes = tree.query(X, k=self._k)\n",
    "            for j in tqdm.trange(np.shape(X)[0]):\n",
    "                classes, cl_count = np.unique(self.y[indexes[j]], return_counts = True)\n",
    "                rez[j, classes] = cl_count / np.sum(cl_count)\n",
    "            return rez\n",
    "            \n",
    "    \n",
    "    def score(self, X, y):\n",
    "        return np.mean(self.predict(X)==y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IRIS**\n",
    "\n",
    "В библиотеке scikit-learn есть несколько датасетов из коробки. Один из них [Ирисы Фишера](https://ru.wikipedia.org/wiki/%D0%98%D1%80%D0%B8%D1%81%D1%8B_%D0%A4%D0%B8%D1%88%D0%B5%D1%80%D0%B0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8666666666666667\n",
      "0.8666666666666667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ну как бы не уступает'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = datasets.load_iris()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.1, stratify=iris.target)\n",
    "\n",
    "clf = KNeighborsClassifier(n_neighbors=2, algorithm='brute')\n",
    "my_clf = MyKNeighborsClassifier(n_neighbors=2, algorithm='brute')\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "my_clf.fit(X_train, y_train)\n",
    "\n",
    "print(my_clf.score(X_test, y_test))\n",
    "print(clf.score(X_test,y_test))\n",
    "assert abs(my_clf.score(X_test, y_test) - clf.score(X_test,y_test))<0.005, \"Score must be simillar\"\n",
    "'ну как бы не уступает'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 2 (0.5 балла)**\n",
    "\n",
    "Давайте попробуем добиться скорости работы на fit, predict и predict_proba сравнимой со sklearn для iris.\n",
    "Для этого используем numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 404 µs, sys: 20 µs, total: 424 µs\n",
      "Wall time: 426 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='brute', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=2, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 28 µs, sys: 9 µs, total: 37 µs\n",
      "Wall time: 35 µs\n"
     ]
    }
   ],
   "source": [
    "%time my_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.02 ms, sys: 892 µs, total: 2.91 ms\n",
      "Wall time: 2.05 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2, 0, 1, 0, 1, 0, 1, 1, 2, 1, 0, 1, 2, 0, 1])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.12 ms, sys: 88 µs, total: 1.21 ms\n",
      "Wall time: 1.18 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2, 0, 2, 0, 1, 0, 1, 2, 2, 1, 0, 1, 2, 0, 1])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time my_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.03 ms, sys: 334 µs, total: 1.37 ms\n",
      "Wall time: 1.12 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0. , 0. , 1. ],\n",
       "       [1. , 0. , 0. ],\n",
       "       [0. , 0.5, 0.5],\n",
       "       [1. , 0. , 0. ],\n",
       "       [0. , 1. , 0. ],\n",
       "       [1. , 0. , 0. ],\n",
       "       [0. , 1. , 0. ],\n",
       "       [0. , 0.5, 0.5],\n",
       "       [0. , 0. , 1. ],\n",
       "       [0. , 1. , 0. ],\n",
       "       [1. , 0. , 0. ],\n",
       "       [0. , 1. , 0. ],\n",
       "       [0. , 0. , 1. ],\n",
       "       [1. , 0. , 0. ],\n",
       "       [0. , 1. , 0. ]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.16 ms, sys: 1.54 ms, total: 3.69 ms\n",
      "Wall time: 2.7 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0. , 0. , 1. ],\n",
       "       [1. , 0. , 0. ],\n",
       "       [0. , 0.5, 0.5],\n",
       "       [1. , 0. , 0. ],\n",
       "       [0. , 1. , 0. ],\n",
       "       [1. , 0. , 0. ],\n",
       "       [0. , 1. , 0. ],\n",
       "       [0. , 0.5, 0.5],\n",
       "       [0. , 0. , 1. ],\n",
       "       [0. , 1. , 0. ],\n",
       "       [1. , 0. , 0. ],\n",
       "       [0. , 1. , 0. ],\n",
       "       [0. , 0. , 1. ],\n",
       "       [1. , 0. , 0. ],\n",
       "       [0. , 1. , 0. ]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time my_clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Задание 3 (1 балл)\n",
    "Добавьте algorithm='kd_tree' в реализацию KNN (использовать KDTree из sklearn.neighbors). Необходимо добиться скорости работы на fit,  predict и predict_proba сравнимой со sklearn для iris.\n",
    "Для этого используем numpy. Score не должен уступать значению KNN из sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors=2, algorithm='kd_tree')\n",
    "my_clf = MyKNeighborsClassifier(n_neighbors=2, algorithm='kd_tree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.1, stratify=iris.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 855 µs, sys: 222 µs, total: 1.08 ms\n",
      "Wall time: 873 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='kd_tree', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=2, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31 µs, sys: 19 µs, total: 50 µs\n",
      "Wall time: 47 µs\n"
     ]
    }
   ],
   "source": [
    "%time my_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.85 ms, sys: 158 µs, total: 2.01 ms\n",
      "Wall time: 1.89 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 2, 2, 2, 0, 0, 1, 2, 1, 1, 2, 2, 0, 1])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.95 ms, sys: 1.38 ms, total: 3.33 ms\n",
      "Wall time: 2.02 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 2, 2, 2, 0, 0, 1, 2, 1, 1, 2, 2, 0, 1])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time my_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.96 ms, sys: 850 µs, total: 2.81 ms\n",
      "Wall time: 4.68 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 3611.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.29 ms, sys: 2.99 ms, total: 8.27 ms\n",
      "Wall time: 8.56 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time my_clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9333333333333333\n",
      "0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "print(my_clf.score(X_test, y_test))\n",
    "print(clf.score(X_test,y_test))\n",
    "assert abs(my_clf.score(X_test, y_test) - clf.score(X_test,y_test))<0.005, \"Score must be simillar\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 4 (2.5 балла)**\n",
    "\n",
    "Рассмотрим новый датасет 20 newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsgroups = fetch_20newsgroups(subset='train',remove=['headers','footers', 'quotes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I was wondering if anyone out there could enlighten me on this car I saw\\nthe other day. It was a 2-door sports car, looked to be from the late 60s/\\nearly 70s. It was called a Bricklin. The doors were really small. In addition,\\nthe front bumper was separate from the rest of the body. This is \\nall I know. If anyone can tellme a model name, engine specs, years\\nof production, where this car is made, history, or whatever info you\\nhave on this funky looking car, please e-mail.'"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = newsgroups['data']\n",
    "target = newsgroups['target']\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11314"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Переведите во всех документах все буквы в нижний регистр и замените во всех документах символы, не\n",
    "являющиеся буквами и цифрами, на пробелы. Далее разбейте текста по пробельным символам на токены(термы/слова). Удалите текста, содержащие только пробелы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i\n"
     ]
    }
   ],
   "source": [
    "data_tok = [text.lower() for text in data]\n",
    "\n",
    "\n",
    "for i in range(len(data_tok)):\n",
    "    data_tok[i] = ''.join([x if(ord('0') <= ord(x) <= ord('9') or ord('a') <= ord(x) <= ord('z')) else ' ' for x in data_tok[i]])\n",
    "    data_tok[i] = data_tok[i].split()\n",
    "\n",
    "i = 0\n",
    "n = len(data_tok)\n",
    "while i < n:\n",
    "    if data_tok[i] == []:\n",
    "        del data_tok[i]\n",
    "        target = np.delete(target, i)\n",
    "        n -= 1\n",
    "    else:\n",
    "        i += 1\n",
    "print(data_tok[0][0])\n",
    "# data_tok should be a list of lists of tokens for each line in data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert all(isinstance(row, (list, tuple)) for row in data_tok), \"please convert each line into a list of tokens (strings)\"\n",
    "assert all(all(isinstance(tok, str) for tok in row) for row in data_tok), \"please convert each line into a list of tokens (strings)\"\n",
    "is_latin = lambda tok: all('a' <= x.lower() <= 'z' for x in tok)\n",
    "assert all(map(lambda l: not is_latin(l) or l.islower() , map(' '.join, data_tok))), \"please make sure that you lowercase the data and drop spaced texts\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary = set()\n",
    "# for text in data_tok:\n",
    "#     for word in text:\n",
    "#         dictionary.add(word)\n",
    "# dictionary = list(dictionary)\n",
    "# dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразуйте датасет в разреженную матрицу scipy.sparse.csr_matrix, где значение x в позиции (i, j)\n",
    "означает, что в документе i слово j встретилось x раз"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "# indptr = [0]\n",
    "# indices = []\n",
    "# tdata = []\n",
    "# vocabulary = {}\n",
    "# for d in data_tok:\n",
    "#      for term in d:\n",
    "#          index = vocabulary.setdefault(term, len(vocabulary))\n",
    "#          indices.append(index)\n",
    "#          tdata.append(1)\n",
    "#      indptr.append(len(indices))\n",
    "#matrix = csr_matrix((tdata, indices, indptr), dtype=int)\n",
    "vocabulary = {}\n",
    "for d in data_tok:\n",
    "    for term in d:\n",
    "        if term in vocabulary:\n",
    "            vocabulary[term] += 1\n",
    "        else:\n",
    "            vocabulary[term] = 1\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13080\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "13080"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary\n",
    "print(len(vocabulary))\n",
    "jopa = list(vocabulary.items())\n",
    "for (a,b) in jopa:\n",
    "    if  b <= 10:\n",
    "        del vocabulary[a]\n",
    "    if b >= 2000:\n",
    "        del vocabulary[a]\n",
    "len(vocabulary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "jopa = list(vocabulary.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 1, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indptr = [0]\n",
    "indices = []\n",
    "data = []\n",
    "for d in data_tok:\n",
    "    for term in d:\n",
    "        if term not in vocabulary:\n",
    "            continue\n",
    "        index = jopa.index((term, vocabulary[term]))\n",
    "        indices.append(index)\n",
    "        data.append(1)\n",
    "    indptr.append(len(indices))\n",
    "\n",
    "csr_matrix((data, indices, indptr), dtype=int).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = csr_matrix((data, indices, indptr), dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Так мы получили векторное представление наших текстов. Значит можно приступать к задаче обучения модели*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте разбиение выборки для кросс-валидации на 3 фолдах. Разрешено использовать sklearn.cross_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [ 3668  3669  3670 ... 11001 11002 11003] TEST: [   0    1    2 ... 3665 3666 3667]\n",
      "TRAIN: [    0     1     2 ... 11001 11002 11003] TEST: [3668 3669 3670 ... 7333 7334 7335]\n",
      "TRAIN: [   0    1    2 ... 7333 7334 7335] TEST: [ 7336  7337  7338 ... 11001 11002 11003]\n"
     ]
    }
   ],
   "source": [
    "import sklearn as sk\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=3)\n",
    "\n",
    "for train_index, test_index in kf.split(matrix):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = matrix[train_index], matrix[test_index]\n",
    "    y_train, y_test = target[train_index], target[test_index]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<11004x13080 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1063306 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишите метод, позволяющий найти оптимальное количество ближайших соседей(дающее максимальный score в среднем на валидации на 3 фолдах).\n",
    "Постройте график зависимости среднего score от количества соседей. Можно рассмотреть число соседей от 1 до 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "MNB = MultinomialNB()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29171210468920394\n",
      "0.5733369683751364\n",
      "0.8568702290076337\n",
      "0.25081788440567065\n",
      "0.4948200654307524\n",
      "0.7415485278080698\n",
      "0.2538167938931298\n",
      "0.48827699018538717\n",
      "0.7382769901853872\n",
      "0.24482006543075246\n",
      "0.46946564885496184\n",
      "0.7082878953107961\n",
      "0.23745910577971646\n",
      "0.46401308615049075\n",
      "0.6941112322791713\n",
      "0.23582333696837512\n",
      "0.46046892039258447\n",
      "0.693565976008724\n",
      "0.23555070883315157\n",
      "0.46210468920392583\n",
      "0.6900218102508179\n",
      "0.22955288985823338\n",
      "0.4531079607415486\n",
      "0.6832061068702291\n",
      "0.23200654307524538\n",
      "0.4558342420937841\n",
      "0.6780261723009815\n",
      "0.22955288985823338\n",
      "0.44929116684841874\n",
      "0.6695747001090513\n",
      "1\n",
      "0.28562340966921124\n"
     ]
    }
   ],
   "source": [
    "ansi = -1\n",
    "max_av_score = 0.0\n",
    "for i in range(1, 11):\n",
    "    av_score = 0.0\n",
    "    for train_index, test_index in kf.split(matrix):\n",
    "        X_train, X_test = matrix.toarray()[train_index], matrix.toarray()[test_index]\n",
    "        y_train, y_test = target[train_index], target[test_index]\n",
    "        \n",
    "        MyKNN= KNeighborsClassifier(n_neighbors=i, algorithm='brute')\n",
    "        MyKNN.fit(X_train, y_train)\n",
    "        av_score += MyKNN.score(X_test, y_test)\n",
    "        print(av_score)\n",
    "        del X_train, X_test, y_train, y_test, MyKNN\n",
    "    av_score /= 3\n",
    "    \n",
    "    if av_score > max_av_score:\n",
    "        max_av_score = av_score\n",
    "        ansi = i\n",
    "    gc.collect()\n",
    "print(ansi)\n",
    "print(max_av_score)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как изменится качество на валидации, если:\n",
    "\n",
    "1. Используется косинусная метрика вместо евклидовой.\n",
    "2. К текстам применяется TfIdf преобразование( sklearn.feature_extraction.text.TfidfTransformer)\n",
    "\n",
    "Сравните модели, выберите лучшую."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим  теперь test  часть нашей выборки и преобразуем её аналогично с train частью. Не забудьте, что наборы слов в train и test части могут отличаться."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsgroups = fetch_20newsgroups(subset='test',remove=['headers','footers', 'quotes'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценим качество(score) вашей лучшей модели на test части датасета. Отличается ли оно от кросс-валидации? Попробуйте сделать выводы, почему отличается качество."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
